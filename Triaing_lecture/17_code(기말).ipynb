{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     CO(GT)  PT08.S1(CO)  PT08.S2(NMHC)  NOx(GT)  \\\n",
      "Datetime                                                           \n",
      "2004-03-10 18:00:00     2.6       1360.0         1046.0    166.0   \n",
      "2004-03-10 19:00:00     2.0       1292.0          955.0    103.0   \n",
      "2004-03-10 20:00:00     2.2       1402.0          939.0    131.0   \n",
      "2004-03-10 21:00:00     2.2       1376.0          948.0    172.0   \n",
      "2004-03-10 22:00:00     1.6       1272.0          836.0    131.0   \n",
      "\n",
      "                     PT08.S3(NOx)  NO2(GT)  PT08.S4(NO2)  PT08.S5(O3)    RH  \\\n",
      "Datetime                                                                      \n",
      "2004-03-10 18:00:00        1056.0    113.0        1692.0       1268.0  48.9   \n",
      "2004-03-10 19:00:00        1174.0     92.0        1559.0        972.0  47.7   \n",
      "2004-03-10 20:00:00        1140.0    114.0        1555.0       1074.0  54.0   \n",
      "2004-03-10 21:00:00        1092.0    122.0        1584.0       1203.0  60.0   \n",
      "2004-03-10 22:00:00        1205.0    116.0        1490.0       1110.0  59.6   \n",
      "\n",
      "                         AH  C6H6(GT)  \n",
      "Datetime                               \n",
      "2004-03-10 18:00:00  0.7578      11.9  \n",
      "2004-03-10 19:00:00  0.7255       9.4  \n",
      "2004-03-10 20:00:00  0.7502       9.0  \n",
      "2004-03-10 21:00:00  0.7867       9.2  \n",
      "2004-03-10 22:00:00  0.7888       6.5  \n",
      "Using matplotlib backend: Qt5Agg\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "def parser(x):\n",
    "    return datetime.strptime(x, '%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "input_file = './data/AirQualityUCI_refined.csv'\n",
    "\n",
    "df = pd.read_csv(input_file,\n",
    "                 index_col=[0],\n",
    "                 parse_dates=[0],\n",
    "                 date_parser=parser)\n",
    "print(df.head())\n",
    "\n",
    "# Visualization setup\n",
    "%matplotlib\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set()\n",
    "\n",
    "%config InlineBackend.figure_format = 'svg'\n",
    "plt.rcParams['figure.figsize'] = [10, 5]\n",
    "plt.ion() # enable the interactive mode\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling: Standardization\n",
    "\n",
    " - 표준화(또는 Z-score.정규화): 표준편차를 기반으로 스케일링 수행\n",
    "     - 데이터가 정규분포를 따른다고 가정하고, 분포가 0을 중심으로 하고 표준편차가 1이 되도록 스케일링 수행\n",
    "     - 변수마다 표준편차가 다를 경우 스케일링 결과(값 범위)가 다를 수 있음\n",
    "     - 이상치에 영향을 덜 받는 스케일링 방법"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scaling: Others\n",
    "\n",
    " - 그 외의 스케일링 기법\n",
    "     - Max Abs Scaler\n",
    "     - Robust Scaler\n",
    "     - Quantile Tansformer Scaler\n",
    "     - Power Tansformer Scaler\n",
    "     - Unit Vector Scaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping Operations\n",
    "\n",
    " - 깔끔한 데이터(tidy data): 데이터 분석 / 머신러닝에 적합한 데이터의 형태"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Grouping Operations: Pivot Table\n",
    "\n",
    " - 피벗 테이블: 개별 데이터 항목들의 집계 및 테이블 재구조화를 통해 데이터의 요약된(그룹호된) 결과를 나타내는 테이블\n",
    "     - 트랜잭션 데이터(예: 계좌이체 내역)를 tidy 형태의 데이터로 변환할 때 활용"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature Split\n",
    "\n",
    " - 특징 분할: 복합적인 값으로 구성된 특징 값을 여러개의 값으로 분할\n",
    "     - Ex. 정제되지 않은 문자열의 토그나이징(tokenizing)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "movies = pd.Series([\"The Godfather, 1972, Francis Ford Coppola\",\n",
    "                  \"Contact, 1997, Robert Zemeckis\",\n",
    "                  \"Parasite, 2019, Joon-ho Bong\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "lst_title = []\n",
    "lst_year = []\n",
    "lst_director = []\n",
    "\n",
    "for val in movies:\n",
    "    title, year, director = val.split(',')\n",
    "    lst_title.append(title)\n",
    "    lst_year.append(year)\n",
    "    lst_director.append(director)\n",
    "# print(lst_title)\n",
    "# print(lst_year)\n",
    "# print(lst_director)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>year</th>\n",
       "      <th>director</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Godfather</td>\n",
       "      <td>1972</td>\n",
       "      <td>Francis Ford Coppola</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Contact</td>\n",
       "      <td>1997</td>\n",
       "      <td>Robert Zemeckis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Parasite</td>\n",
       "      <td>2019</td>\n",
       "      <td>Joon-ho Bong</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           title   year               director\n",
       "0  The Godfather   1972   Francis Ford Coppola\n",
       "1        Contact   1997        Robert Zemeckis\n",
       "2       Parasite   2019           Joon-ho Bong"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_movie = pd.DataFrame()\n",
    "df_movie['title'] = lst_title\n",
    "df_movie['year'] = lst_year\n",
    "df_movie['director'] = lst_director\n",
    "\n",
    "df_movie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Why Is Feature Selection Important?\n",
    "\n",
    " - 특징 수가 많을수록 비선형 문제에 적합한 모델 생성이 가능, BUT\n",
    " - 차원의 저주(curse of dimensionality)\n",
    "     - 특징 수가 증가할수록, 모델링에 필요한 데이터 수는 지수적으로(exponentially) 증가 -> 특징 수가 필요 이상으로 많은 경우 모델 성능에 악영향"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recap: Feature Extraction and Selection\n",
    " - 특징 추출\n",
    "     - 데이터의 다양한 조작을 통해 모델 학습에 적합한 특징들을 생성\n",
    " - 특징 선택(또는 변수 선택)\n",
    "     - 전체 특징 집합 중에서 모델 학습에 필요한 부분 집합을 선택\n",
    "     - 모델이 해결하고자 하는 문제와 상관없는 특징 = 노이즈\n",
    "     - 효과적인 특징 선택 -> 빠른 학습, 복잡도 감소, 해석이 용이함, 모델의 성능 향상\n",
    "     - 특징 선택 방법 종류 : 일변량 특징 선택, 다변량 특징 선택"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate Feature Selection\n",
    "\n",
    " - 일변량 특징 선택: 개별 특징 단위로 평가 및 선택\n",
    "     - 수동 작업: 도메인 지식을 가진 사람이 직접 특징을 선별 -> 많은 시간 소요\n",
    "     - 분산 검사: 임계치보다 낮은 분산을 보이는 특징 제거(Ex. 분산 = 0인 특징 제거)\n",
    "     - 피어슨 상관계서: 대산 변수(target variable)와 특징 간의 상관관계를 수치화"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Thumb Rule to Use the Pearson Correlation\n",
    "\n",
    " - 특징 선택을 위한 피어슨 상관계수 활용\n",
    "     - 대상 변수와 어느 정도 상관성을 갖는 특징을 선택 (상관계수가 0에 가까운 특징 = 예측력이 거의 없음.)\n",
    " - 두 특징 간 상관성이 너무 강한 경우 : 둘 중 하나만 선택\n",
    "     - 상관성이 강한 두 특징은 중복된 특징과 다름 없다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate for entire data\n",
    "df.interpolate(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Correlation Matrix\n",
    "\"\"\"\n",
    "sns.pairplot(df, kind = 'reg', diag_kind = 'kde',\n",
    "            plot_kws = {'scatter_kws' : {'alpha' : 0.1}})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Feature Selection\n",
    "\n",
    " - 다변량 특징 선택: 다수의 특징으로 구성된 집합을 평가 및 선택\n",
    "     - 데이터셋에 특징이 너무 많은 경우(Ex. 수백 또는 수천개)\n",
    " - 대표적 방법\n",
    "     - Filter 방식\n",
    "     - Wrapper 방식\n",
    "     - Embedded 방식"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Filter Method\n",
    "\n",
    " - 통계적 방법을 통해 특징들을 스코어링(scoring)하는 방식\n",
    "     - 스코어링 기군: 특징 - 대상 변수와의 상관관계\n",
    "     - 점수가 가장 높은 n개의 특징을 선택\n",
    " - 특징 선택을 위한 통계적 방법\n",
    "     - 피어슨 상관계수(Pearson Correlation Coefficient)\n",
    "     - 선형 판별 분석(LDA): 분류 성능을 보존하는 방향으로 차원 축소\n",
    "         - 특징(연속형) - 대상변수(범주형) 조합인 경우에 적용 가능\n",
    "     - 분산 분석(ANOVA): 특징 간 분산간의 관계를 분석\n",
    "         - 특징(범주형) - 대상변수(연속형) 조합인 경우에 적용 가능\n",
    "     - 카이제곱 검중(Chi-squared Test): 빈도 분포를 기반으로 범주형 변수간 상관성 평가\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapper Method\n",
    "\n",
    " - 모델을 사용하여 특징 집합을 테스트/수정하면서 최적의 특징 조합을 구성\n",
    "     - 반복적 모델 생성/테스트를 요구하므로 많은 시간이 필요함\n",
    "         - 특징 공간이 방대할 경우 가능한 모든 특징 조합들을 테스트하기 어려움\n",
    "     - 탐색 문제로 귀결되므로, 시간 & 공간 비용에 제약사항을 가짐.\n",
    " - 대표적 방법\n",
    "     - Forward Selection\n",
    "     - Backward Elimination\n",
    "     - Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wrapper Method: Forward Selection\n",
    "\n",
    " - 중요도가 높은 특징부터 추가하는 방식\n",
    "     - 정지 조건을 만족할 때까지 한 개씩 추가\n",
    "         - 정지 조건 Ex. 모델 성능의 하락\n",
    "     - 계산 비용이 낮은 편\n",
    "     - 이미 선택된 특징은 제거되지 않음."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedded Method\n",
    "\n",
    " - 학습 알고리즘 자체에 특징 선택 기능이 구현된 방식\n",
    "     - Filter와 Wrapper 방식의 장점을 결합\n",
    "     \n",
    " - 대표적 알고리즘\n",
    "     - Random Forest\n",
    "     - Gradient Boosting Machine (GBM)\n",
    "     - LASSO, RIDGE: 특징 가중치에 페털티 부여 -> 중요도가 낮은 특징 무력화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Prepare a feature set\n",
    "X = df.iloc[:, 1:]    # input features\n",
    "X\n",
    "\n",
    "y = df.iloc[:, 0]    # target variable\n",
    "y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\"\"\"\n",
    "Feature Importance\n",
    "\"\"\"\n",
    "\n",
    "# Create and train model for regression\n",
    "\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "model = RandomForestRegressor()\n",
    "model.fit(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Print feature importances\n",
    "print(model.feature_importances_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Plot the feature importances\n",
    "feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "feat_importances.nlargest(10).plot(kind='barh')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
